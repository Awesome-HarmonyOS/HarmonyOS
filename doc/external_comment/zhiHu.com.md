# 本文件内容为来源于[知乎](zhihu.com)的消息，不保障内容的完整与准确性，仅供参考
## 如有侵权，请新建issue
## 1. 「“内部消息”」
  - 来源[知乎](https://www.zhihu.com/question/339615503/answer/789326145) [@默然](https://www.zhihu.com/people/moranzcw) 
  > 谢邀。 
  > 
  > ~~ 先狗头保命。（提示：此回答有加密内容）~~ 
  >  
  >  
  > 以下内容为全网独家消息，转述自项目相关员工，信息量远高于各路KOL，自媒体。
   > 
   > 关键词：
   > 
   > 原生标记句法语言（Native Marked Syntax Language）
   > 热点换页算法（Boiling Point Page Swap Algorithm）
   > 反抢占式调度算法（Anti-Navy Preemptive Algorithm）
   > 原生高级矢量指令（Native Advanced Instruction in Vector Edition）
   > 共享基技术（Shared Base）
   > 我看知乎上这么多开发者都在抱怨鸿蒙，其实没必要这么激动。
   > 
   > 我非常理解开发者现在的心情，毕竟发布会约等于什么都没讲。
   > 
   > 如果你是开发者的话，先不要点反对，这篇文章绝对有你要找的东西。。
   > 
   > 华为的技术一直都还可以，这次发布会的问题是没有请项目负责人来讲解，余本身也多年不碰技术，让他讲ppt，其实不是个正确选择。
   > 
   > 正好我周围有几个华为的朋友，工作跟鸿蒙相关。前后问了很多东西，很涨姿势，这里分享给大家。都是要公开的东西，也不存在泄密。而且也不涉及具体技术实现。
   > 
   > 现在很多人说开发者大会连一点文档，开发工具都没放出来，连用什么语言都不知道。目前开发工具确实没准备好。但是已经很有进展了。
   > 
   > 朋友的同事A，目前在做形式语言及相关理论的研究。
   > 这次发布会强调统一IDE支撑一次开发，多端部署，可以实现跨终端生态共享。
   > 
   > A所在的组正在设计鸿蒙的开发语言，以及相关的开发工具，这次华为不打算用Java，而是基于超文本标记语言改进，设计了一套全新的语言。叫做原生标记句法语言（Native Marked Syntax Language），简称NMS语言。 这是解释型语言。
   > 
   > 很多人会说，解释型语言不是很慢吗？是的。
   > 
   > 但是解释型语言可以降低新手的学习门槛，对开发者友好，现在鸿蒙需要生态，要吸引开发者，只能这样做。
   > 
   > 但不用担心，这次NMS也会纳入方舟项目，采用的是解释器+预编译技术，后期会慢慢更换为纯编译。性能上有望接近C++和Rust。
   > 
   > A其实是个神人，属于特别有天分的那种，他初中时，在一次算法比赛中，他用C++写出了O(1/N)时间复杂度的算法，当时编译没有通过，他非常愤怒，锤了一下电脑，然后编译器链接错误，于是他只能现场用机器语言写一个非常粗糙的编译器来编译程序，最后比冠军晚提交了5秒，只拿了亚军。
   > 
   > 后来就喜欢上了编译原理，高一之前就把龙书虎书鲸书都读完了。直到现在还沉迷在编译技术中。整天想着怎么改进haskell和Lisp。
   > 
   > 这次他在新语言的解释器里贡献了相当多的代码。（据 @Bricklayer 的内幕消息：方舟编译器将比GCC多一个级别的优化选项，-O4优化，仅内部使用。此选项为云优化，编译时代码将上传到A的服务器上，由A亲自优化）
   > 朋友B，做安全的。他算是大学就一起玩的死党了，上文和后文的同事，其实都是他的同事，我们玩到一起了而已。
   > 
   > 他老大非常牛逼，是华为花大价钱挖过来的白帽子。发布会上说的基于微内核架构提升设备安全性，其实就跟他们组有关。
   > 
   > 讲大了就泛泛而谈了，所以我就讲一个点。
   > 
   > 如果提到CPU的安全性问题，很多开发者会想起去年初爆出的Meltdown和Spectre漏洞，目前Intel和AMD在售的CPU，几乎都中招，一时间人心惶惶。
   > 
   > 简单介绍下这两个漏洞吧。
   > 
   > 现代的CPU，不管是x86还是Arm，都使用分支预测技术（Branch Prediction），CPU会在执行if语句，流水线闲置等待的时候猜测一个分支并执行，预测失败就恢复，执行对的分支。因为程序具有局部性，加速效果非常明显。
   > 
   > 没这个技术，现在的CPU速度至少降低一半
   > 
   > 现代操作系统还有虚拟内存，进程之间无法直接访问对方的内存，这方便管理，并且保证数据安全。
   > 
   > 这本来是没有什么问题的。
   > 
   > 问题出在缓存上，当分支预测失败时，CPU会恢复到执行之前的状态，这在逻辑上没有问题，但是现代CPU出于性能考虑，不会恢复缓存。也就是说，一次分支预测之后执行的代码，导致一些数据加载到缓存了，如果分支预测失败，这些缓存是不会主动退回的。
   > 
   > 但是缓存访问更快，内存慢，如果某个恶意程序被执行，并且跟普通进程有内存共享机制。那么恶意程序可以引导普通进程进行特殊地址的访问，然后恶意程序测量访问速度，猜出访问的是缓存还是内存。进阶版本的实现甚至可以dump普通进程的整个内存映像。这是一种旁路攻击。
   > 
   > 本来硬件的漏洞，在操作系统层面是没法修复的，只能补救。如果要软件修复，要不就是不能完全抵御攻击，要不是就是牺牲大部分CPU性能。
   > 
   > 朋友B所在的组基本上以很小的代价，解决了这个问题，而且这项技术未来也会应用在鸿蒙OS上，这点上其实可以稍微吹一吹，因为目前Windows和Linux都没做到这点。具技术原理我没听太懂，大致是预先训练一个模型，通过识别进程上下文，提前预判程序的执行流程，可以达到跨秒的预测，大幅降低预测失败的可能性，这叫热点换页算法（Boiling Point Page Swap Algorithm）。
   > 
   > 再说说当年他老大怎么进来的。
   > 
   > 面试现场，面试官问了个网络安全的问题，然后老大看到面试官的Thinkpad装的是Kali Linux，想着就不用啰嗦了，直接上手干，实力说话。于是老大就用那台thinkpad在面试期间拿下了华为一个生产环境的数据库，差点拖库了。虽然不是什么核心的服务器，算不上重大事故，但面试官一下子就拍板，涨了一倍薪水，把人要了。所以是一战成名。
   > 
   > 朋友的同事C，这也是个神人，骚话特别多，喜欢玩各种底层的轮子，之前混币圈的，主要是做分布式，其实就是挖矿。
   > 
   > 觉得没意思了，来了华为，这次鸿蒙的分布式架构有他参与。
   > 
   > 最近他们在测试鸿蒙同时在100台终端上的协同计算能力。测试方式没定，他问老大，老大说跑深度学习？算了，不是特别熟。那挖矿吧，毕竟之前就玩这个。老大就答应了。
   > 
   > 然后充分利用了鸿蒙的特性，写了很多指令级优化，比如通过提高数据访问的局部性来提高缓存命中率，使用循环展开来提高整数和浮点单元，及流水线的占用率。还充分利用了CPU的SIMD技术。其中由一种麒麟芯片的扩展指令，原生高级矢量指令（Native Advanced Instruction in Vector Edition）支持2048位宽度的矢量运算，高于Intel的AVX2扩展指令，能做到高度的数据并行。
   > 
   > 最后通过共享基技术（Shared Base）部署到100台机器上。单台机器的运算速度优化到了之前的1.7倍。
   > 
   > 因为有如此大的提升，他当时没反应过来，一下子没法相信，还以为程序出错了，根本就没算出正确结果。于是他心算了一波非对称加密的密钥，和程序结果比较，发现其实都是对的。这波优化其实相当漂亮，在内部还专门做了场报告，而发布会根本没有提。
   > 
   > 最后再说说发布会上宣传的低延时引擎，其实实时系统的低延时不是什么值得吹的性能，如果连低延时都做不到，那就不叫实时系统了。就像汽车有四个轮子一样，这算不上feature。
   > 
   > 只是这次鸿蒙用了全新的调度算法，反抢占式调度算法（Anti-Navy Preemptive Algorithm）。
   > 
   > 以往的实时系统可以保证低延时，但是没办法保证CPU占用率，这次鸿蒙做到了既可以运行实时任务，还能尽可能榨干CPU的剩余性能，保证CPU空转等待的概率降到最低。
   > 
   > 这部分在发布会上就是一笔带过，难怪这么多人不满意了。
   > 
   > 总体来说，华为技术可以，但这次发布会完全就是翻车现场。对着一堆已经写进教科书的技术吹，而自己做的东西一点都没讲。这恰好满足一部分外行半懂不懂喜欢虚荣的心理，但又让开发者感到蒙蔽：这都是正确但无卵用的废话，说了半天等于啥都没说啊。

